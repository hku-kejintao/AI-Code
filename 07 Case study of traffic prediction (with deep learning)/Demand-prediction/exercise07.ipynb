{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Please always run this cell first to set up the environment\n",
    "# Especially important when running in Google Colab\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # noqa: F401\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "    print(\"Running in Google Colab environment\")\n",
    "\n",
    "    REPO_NAME = \"AI-Code\"\n",
    "    REPO_URL = \"https://github.com/hku-kejintao/AI-Code.git\"\n",
    "    LESSON_DIR = \"07 Case study of traffic prediction (with deep learning)/Demand-prediction\"\n",
    "\n",
    "    BASE_DIR = Path(\"/content\")\n",
    "    REPO_PATH = BASE_DIR / REPO_NAME\n",
    "    LESSON_PATH = REPO_PATH / LESSON_DIR\n",
    "\n",
    "    os.chdir(BASE_DIR)\n",
    "    if not REPO_PATH.exists():\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        print(\"Repository already exists, skip cloning.\")\n",
    "\n",
    "    if not LESSON_PATH.exists():\n",
    "        available = [p.relative_to(REPO_PATH) for p in REPO_PATH.rglob(\"*\") if p.is_dir()]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Lesson directory not found:\\n  {LESSON_DIR}\\n\\n\"\n",
    "            f\"Available directories under repo:\\n  \"\n",
    "            + \"\\n  \".join(map(str, available[:20]))\n",
    "        )\n",
    "    os.chdir(LESSON_PATH)\n",
    "\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "else:\n",
    "    print(\"Running in local / non-Colab environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 07 Traffic Demand Prediction\n",
    "\n",
    "In this exercise, you need to follow the requirements of each question to generate the Python code, and the following example is for reference：\n",
    "\n",
    "- Sample Question: Write a program that takes the user's name as input and prints \"Hello, [name]!\" where [name] is the user's input.\n",
    "\n",
    "- Potential Answer:\n",
    "\n",
    "```python\n",
    "    name = input(\"Enter your name: \")\n",
    "    print(\"Hello, \" + name + \"!\")\n",
    "```\n",
    "- If you enter 'David', the code will output 'Hello, David!', and this will satisfy the requirements.\n",
    "\n",
    "## Attention\n",
    "- Generally, there will be multiple answers for one question and you don't have to strictly follow the instructions in the tutorial, as long as you can make the output of the code meet the requirements of the question.\n",
    "- If possible, strive to make your code concise and avoid excessive reliance on less commonly used libraries.\n",
    "- You may need to search for information on the Internet to complete the excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 01: In this exercise, we use the same dataset as in the tutorial. The code to read the data and split it into training, validation, and test sets has been written for you. Run the following code to prepare the data. We only use the third region's data as dataset to run quickly. You can retrain the model on the full dataset if you want.\n",
    "\n",
    "The feature set's shape should be `[Region, Sample, Features]`, the label set's shape should be `[Region, Sample]`. As we only use one region's data here, the first dim should be equal to 1 for both frature and label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "demand = np.load('./10min_demand_in_manhattan.npy')\n",
    "demand = demand[2, :].reshape(1, -1)  # Remove this line to use the data of all regions if you want.\n",
    "def construct_dataset(demand, hourly_trend=12, daily_trend=7, weekly_trend=4):\n",
    "    X, y = [], []\n",
    "    hour_range, day_range, week_range = 60 // 30, 24 * 60 // 30, 7 * 24 * 60 // 30\n",
    "    for i in range(demand.shape[0]): # for each region\n",
    "        X_1region, y_1region = [], []\n",
    "        # here we leave 30 days for constructing the dataset\n",
    "        for j in range(30*day_range, demand.shape[1]): # for each instance\n",
    "            y_1region.append(demand[i, j])\n",
    "            hour_trend = demand[i, j-hourly_trend*hour_range : j]\n",
    "            day_trend = demand[i, list(range(j-daily_trend*day_range, j, day_range))]\n",
    "            week_trend = demand[i, list(range(j-weekly_trend*week_range, j, week_range))]\n",
    "            X_1region.append(np.concatenate([hour_trend, day_trend, week_trend]))\n",
    "        X.append(X_1region)\n",
    "        y.append(y_1region)\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X, y = construct_dataset(demand, hourly_trend=12, daily_trend=7, weekly_trend=4)\n",
    "\n",
    "day_range = 24 * 60 // 30\n",
    "X_train, X_test = X[:, :-14*day_range, :], X[:, -14*day_range:, :]\n",
    "y_train, y_test = y[:, :-14*day_range], y[:, -14*day_range:]\n",
    "\n",
    "print('Training set size: ', X_train.shape, y_train.shape)  \n",
    "print('Test set size: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02: Fit the traffic demand data using a full connection neural network on the training set. Make predictions using the test set and calculate the MAE, RMSE, and MAPE of the predictions. Output these metrics.\n",
    "\n",
    "#### Question 02.1: The following code will help you convert data into a torch dataloader. Please set an appropriate batch size at the beginning, and then run the cell to get the `train_loader` and `test_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =   # Choose a proper batch size here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "def get_dataloader(X, y, device, bs, shuffle):\n",
    "    return DataLoader(TensorDataset(torch.FloatTensor(X).to(device), torch.FloatTensor(y).to(device)), \n",
    "        batch_size=bs,\n",
    "        shuffle=shuffle, \n",
    "        drop_last=False)\n",
    "train_loader = get_dataloader(X_train.reshape(-1, X_test.shape[2]), y_train.reshape(-1,1), device, batch_size, True)\n",
    "test_loader = get_dataloader(X_test.reshape(-1, X_test.shape[2]), y_test.reshape(-1,1), device, batch_size, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 02.2: Please write a training function, which should receive the model, optimizer, loss function, number of epochs, training data loader and test data loader as parameters, execute the training process, and output the average loss on the training set and test set after each epoch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, optimizer, loss_fn, epochs, train_loader, test_loader):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 02.3: Please design a full connection neural network, select the appropriate optimizer and loss function, and complete the training. \n",
    "\n",
    "You need to \n",
    "- Define the network structure;\n",
    "- Select a loss function;\n",
    "- Select an optimizer and corresponding learning rate;\n",
    "- Train the model using the training function you defined in the previous question.\n",
    "\n",
    "Some of the code has been written for you. \n",
    "\n",
    "**Try as many different network architectures as possible to find the best model.**\n",
    "\n",
    "**Try to modify the parameters including learning rate, optimization algorithm, number of training epochs, etc. based on what you have learned previously to achieve better model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        # write your code here\n",
    "        \n",
    "        # end of your code\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # write your code here\n",
    "        \n",
    "        # end of your code\n",
    "\n",
    "input_size =   # Choose correct input size here\n",
    "epochs =   # Choose proper number of epochs here\n",
    "loss_fn =   # Choose proper loss function here\n",
    "model = Net(input_size=input_size).to(device)\n",
    "optimizer =   # Choose proper optimizer and learning rate here\n",
    "trainer(model, optimizer, loss_fn, epochs, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 02.4: Combine all the data (training set and test set) into one dataset, use the trained model to make predictions, and plot the ground truth and your predictions on the same graph to show the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 03: Fit the traffic demand data using a LSTM network on the training set. Make predictions using the test set and calculate the MAE, RMSE, and MAPE of the predictions. Output these metrics.\n",
    "\n",
    "#### Question 03.1: The following code will help you convert the data into the data format required for the time series prediction task and build the torch dataloader. Please set an appropriate batch size and train/test ratio at the beginning, and then run the cell to get the `train_loader` and `test_loader`.\n",
    "\n",
    "Like GRU in the tutorial, the feature set's shape for LSTM should be `[Sample, Series, Feature]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =   # Please choose a proper batch size here\n",
    "train_test_ratio =   # Please choose a proper train test ratio here\n",
    "\n",
    "timeseries = demand.reshape(-1, 1)\n",
    "train_size = int(len(timeseries) * train_test_ratio)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]\n",
    "\n",
    "def create_time_dataset(dataset, lookback=240):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback-2):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    X = torch.tensor(np.array(X)).to(device)\n",
    "    y = torch.tensor(np.array(y)).to(device)\n",
    "    y = y[:, -1, :]\n",
    "    return X, y\n",
    "\n",
    "train_X, train_y = create_time_dataset(train, lookback=240)\n",
    "test_X, test_y = create_time_dataset(test, lookback=240)\n",
    "\n",
    "print('Training set size: ', train_X.shape, train_y.shape)\n",
    "print('Test set size: ', test_X.shape, test_y.shape)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_X, train_y), shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(test_X, test_y), shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 03.2: Please design a LSTM network, select the appropriate optimizer and loss function, and complete the training. \n",
    "\n",
    "You need to \n",
    "- Define the network structure;\n",
    "- Select a loss function;\n",
    "- Select an optimizer and corresponding learning rate;\n",
    "- Train the model using the training function you defined in the previous question.\n",
    "\n",
    "Some of the code has been written for you. \n",
    "\n",
    "**Try as many different network architectures as possible to find the best model.**\n",
    "\n",
    "**Try to modify the parameters including learning rate, optimization algorithm, number of training epochs, etc. based on what you have learned previously to achieve better model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # write your code here\n",
    "        \n",
    "        # end of your code\n",
    "\n",
    "    def forward(self, x):\n",
    "        # write your code here\n",
    "        \n",
    "        # end of your code\n",
    "\n",
    "\n",
    "lr =   # Please choose a proper learning rate here\n",
    "epochs =   # Please choose a proper number of epochs here\n",
    "model = LstmModel().to(device)\n",
    "optimizer =   # Choose a proper optimizer and learning rate here\n",
    "loss_fn =   # Choose a proper loss function here\n",
    "trainer(model, optimizer, loss_fn, epochs=epochs, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 03.3: Combine all the data (training set and test set) into one dataset, use the trained model to make predictions, and plot the ground truth and your predictions on the same graph to show the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Question 04: Predict the traffic demand data of all regions using a GCN network. Output the metrics. A NumPy file named \"edges_GAman.npy\" contains edge information of a road network.\n",
    "\n",
    "The data of graph neural network includes node information and edge information. The shape of node information should be `[number of nodes, number of features on one node]`, and the shape of edge information should be `[2, num of edges]` in the form of an array of `(edge ​​starting point, edge end point)`. \n",
    "\n",
    "This task is a node prediction task, the label shape should be `[number of nodes, number of labels on one node]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "edge_index = np.load(\"./edges_GAman.npy\")\n",
    "traffic_data = np.load(\"./10min_demand_in_manhattan.npy\")\n",
    "\n",
    "num_regions, num_time_steps = traffic_data.shape\n",
    "\n",
    "def create_graph_data(traffic_data, edge_index, history_steps=4):\n",
    "    edge_index = torch.tensor(edge_index.T, dtype=torch.long)\n",
    "    data_list = []\n",
    "    for t in range(history_steps, num_time_steps):\n",
    "        x = traffic_data[:, t-history_steps:t]\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        y = traffic_data[:, t]\n",
    "        y = torch.tensor(y, dtype=torch.float).reshape(-1, 1)\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "history_steps = 20\n",
    "data_list = create_graph_data(traffic_data, edge_index, history_steps)\n",
    "dataset_size = len(data_list)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data_list, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    print(\"Batch node feature shape:\", batch.x.shape)\n",
    "    print(\"Batch edge index shape:\", batch.edge_index.shape)\n",
    "    print(\"Batch target shape:\", batch.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficGCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=16, output_dim=1):\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "    \n",
    "\n",
    "gcn = TrafficGCN(input_dim=history_steps).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    \n",
    "\n",
    "\n",
    "def test_model(model, dataloader, device):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = \n",
    "epochs = \n",
    "optimizer = \n",
    "loss_fn = \n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_model(gcn, train_loader, optimizer, loss_fn, device)\n",
    "    test_loss = test_model(gcn, test_loader, device)\n",
    "    print(f\"Epoch {epoch}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

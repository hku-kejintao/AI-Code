{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06 Convolutional Neural Networks\n",
    "\n",
    "In this exercise, you need to follow the requirements of each question to generate the Python code, and the following example is for referenceï¼š\n",
    "\n",
    "- Sample Question: Write a program that takes the user's name as input and prints \"Hello, [name]!\" where [name] is the user's input.\n",
    "\n",
    "- Potential Answer:\n",
    "\n",
    "```python\n",
    "    name = input(\"Enter your name: \")\n",
    "    print(\"Hello, \" + name + \"!\")\n",
    "```\n",
    "- If you enter 'David', the code will output 'Hello, David!', and this will satisfy the requirements.\n",
    "\n",
    "## Attention\n",
    "- Generally, there will be multiple answers for one question and you don't have to strictly follow the instructions in the tutorial, as long as you can make the output of the code meet the requirements of the question.\n",
    "- If possible, strive to make your code concise and avoid excessive reliance on less commonly used libraries.\n",
    "- You may need to search for information on the Internet to complete the excercise.\n",
    "\n",
    "Firstly, following codes can help you import necessary packages that will be used in this exercise and choose proper device to accelerate the training and testing process of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 01 (Dataset and Dataloader):\n",
    "\n",
    "We are using **CIFAR10** dataset for this exercise. Here are some basic information about this dataset\n",
    "\n",
    "- CIFAR-10 dataset consists of 60,000 images divided into 10 classes.\n",
    "- Each class contains 6000 images, 5000 for training and 1000 for testing.\n",
    "- The images are colored and of size 32x32 pixels.\n",
    "- The 10 different classes represent airplane, car, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
    "\n",
    "As one of the most commonly used baseline datasets in the field of computer vision, the `torchvision.dataset` module provides quick access to the CIFAR10 dataset\n",
    "\n",
    "The `torchvision.datasets` module contains Dataset objects for many real-world vision data including MNIST, CIFAR, etc. In this tutorial, we use the MNIST dataset.\n",
    "\n",
    "### Question 01.1 (Dataset and Dataloader Construction, Batch Size)\n",
    "Please set an appropriate batch size, obtain the CIFAR10 dataset through the Pytorch API, and build the data loader. We have prepared code for downloading data and build dataloader for you. You only need to choose `BATCH_SIZE`. Write your answer in the following code frame:\n",
    "\n",
    "**The code may take some time to download the first time it is executed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = \n",
    "\n",
    "# Loading MNIST dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Only use a subset of the dataset for training and testing\n",
    "train_subset = Subset(train_dataset, list(range(500)))\n",
    "test_subset = Subset(test_dataset, list(range(100)))\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = DataLoader(dataset=train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 01.2 (Check)\n",
    "Run the cell below. If your dataset is named as `train_dataset` and `test_dataset` and the build is complete it should output nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_dataset) == 50000, f\"Expected 50000 train samples, got {len(train_dataset)}\"\n",
    "assert len(test_dataset) == 10000, f\"Expected 10000 test samples, got {len(test_dataset)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 01.3 (Date Visualization, Optional) \n",
    "Please visualize the first batch of data in the training data loader based on the code in the tutorial. Most of the required codes have benn written for you. You need to permute the data to adapt to the requirements of different APIs for the order of image channels at line 14.\n",
    "\n",
    "You may refer to [https://pytorch.org/docs/stable/generated/torch.permute.html](https://pytorch.org/docs/stable/generated/torch.permute.html) to learn how to use `torch.permute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch of the training data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Define the figure\n",
    "grid_size = int(BATCH_SIZE**0.5)\n",
    "rows, cols = grid_size, (BATCH_SIZE + grid_size - 1) // grid_size\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the images in the batch and their corresponding labels\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < BATCH_SIZE:\n",
    "        ax.imshow(images[i].squeeze().permute(__, __, __))  # permute to convert (Channel, Height, Width) to (Height, Width, Channel)\n",
    "        ax.set_title(labels[i].item(), fontsize=8)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide the empty subplot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 02 (CNN)\n",
    "### Question 02.1 (Model Defination): \n",
    "Fill in the appropriate code in the specified location in the cell below to build a convolutional neural network for image classification tasks. *You need to define the layers used in the network and the process of forward propagation of data between layers.* The model structure is:\n",
    "- **conv1**: A 2d convolutional layer that receives 3 channels of input and 16 channels of output, with a convolutional kernel size of 3*3, a stride of 1, and a padding of 0;\n",
    "- **maxpooling3**: A 2d maxpooling layer with a kernel size of 3*3;\n",
    "- **conv2**: A 2d convolutional layer that receives 16 channels of input and 32 channels of output, with a convolutional kernel size of 2*2, a stride of 2, and a padding of 1;\n",
    "- **conv3**: A 2d convolutional layer that receives 32 channels of input and 64 channels of output, with a convolutional kernel size of 3*3, a stride of 1, and padding to keep the feature map size constant;\n",
    "- **maxpooling2**: A 2d maxpooling layer with a kernel size of 2*2;\n",
    "- **flatten**: A layer that flat the feature map of the convolutional layer into a one-dimensional vector;\n",
    "- **fc**: A fully connected layer that transforms a 64\\*3\\*3 dimensional vector into a 10 dimensional vector\n",
    "\n",
    "**Note: We have already written some codes for you. You just need to fill in the appropriate parameters or add a few lines of code in the specified positions.**\n",
    "\n",
    "##### Attention for this question:\n",
    "- Please first complete this question based on the model structure given above. And use this model to complete the subsequent exercises in Question02.\n",
    "- Once you have completed Question02 using the model structure given above, we encourage you to **try as many different model structures as possible to find the best classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN Model\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3 , out_channels=16, kernel_size=3, stride=1, padding=0)\n",
    "        # write your code here to define self.conv2\n",
    "        self.conv2 = \n",
    "        # end of your code\n",
    "        self.conv3 = nn.Conv2d(in_channels=__, out_channels=__, kernel_size=_, stride=_, padding=\"same\")  # fill in the missing parameters, let padding=\"same\" can keep the same feature map size of the input\n",
    "        self.maxpooling2 = nn.MaxPool2d(kernel_size=2)\n",
    "        # write your code here to define self.maxpooling3\n",
    "        self.maxpooling3 = \n",
    "        # end of your code\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpooling3(x)\n",
    "        # write your code here to let the data pass relu-activated conv2, relu-activated conv3 and maxpooling2 without activation sequentially\n",
    "\n",
    "\n",
    "\n",
    "        # end of your code\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN_Model().to(device)\n",
    "# (Optional) If you haven't install torchinfo, you can ignore the codes in this cell below. But TAs recommend you to use torchinfo here as this can help you check if your forward process has set aligned size beteween layers, especially between the last conv layer and the first fully connected layer.\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(BATCH_SIZE, 3, 32, 32), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02.2 (Optimizer, Loss function, Hyperparameters)\n",
    "\n",
    "Please select the appropriate optimizer and loss function for the model. \n",
    "\n",
    "**Try to modify the parameters including learning rate, optimization algorithm, number of training rounds, etc. based on the tutorial to achieve better model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "LR = \n",
    "optimizer = \n",
    "loss = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02.3 (Training Loop and Testing Loop)\n",
    "Please complete the `train` function and the `test` function.\n",
    "\n",
    "- The `train` function receives dataloader, model, loss function, and optimizer as parameters, completes the training of an epoch, including forward propagation, loss function calculation, and back propagation, and outputs training status information at appropriate times during the training process.\n",
    "- The `test` function takes dataloader, model, and loss function as parameters, completes the test of the entire test dataloader, including forward propagation, loss function calculation, prediction accuracy calculation, and outputs the loss and accuracy on the entire test set.\n",
    "- Please add additional code based on the tutorial to return the average loss on the batch during training and the average loss and accuracy on the test set after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # write your code here\n",
    "    \n",
    "    # end of your code\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # write your code here\n",
    "    \n",
    "    # end of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02.4 (Training and Testing)\n",
    "\n",
    "Use the function you defined earlier and select the appropriate number of training epochs to complete training and testing. Record the train loss and validation loss and validation accuracy for each epoch. Then, plot them on a graph together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train_loss, test_loss, test_accuracy = [], [], []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    # write your code here\n",
    "    \n",
    "    # end of your code\n",
    "    \n",
    "\n",
    "# Reuslt Visualization\n",
    "# write your code here\n",
    "    \n",
    "# end of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02.5 (Alignment between Layers)\n",
    "\n",
    "A convolutional neural network is defined below, but some of the parameters of some layers are missing. Please try to complete the network. \n",
    "\n",
    "Modify and run the following cell. If your results are correct, the following cell should not produce runtime errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should only modify the values â€‹â€‹of the following constants.\n",
    "INPUT_CHANNELS = \n",
    "CONV1_OUT_CHANNELS = \n",
    "CONV3_IN_CHANNELS = \n",
    "FC1_IN_FEATURES = \n",
    "FC2_IN_FEATURES = \n",
    "MODEL_OUTPUT_SIZE = \n",
    "# Your modification should end before this comment. \n",
    "# But you may still need to read the rest of the code in this cell to get the information you need to complete the exercise.\n",
    "\n",
    "# Codes below this comment should not be modified.\n",
    "class UncompletedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UncompletedCNN, self).__init__()\n",
    "        # write your code here\n",
    "        self.conv1 = nn.Conv2d(in_channels=INPUT_CHANNELS, out_channels=CONV1_OUT_CHANNELS, kernel_size=3, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(in_channels=CONV3_IN_CHANNELS, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(FC1_IN_FEATURES, 256)\n",
    "        self.fc2 = nn.Linear(FC2_IN_FEATURES, MODEL_OUTPUT_SIZE)\n",
    "        # end of your code\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # write your code here\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpooling(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpooling(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpooling(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "completed_model = UncompletedCNN()\n",
    "try:\n",
    "    model_output = completed_model(torch.rand(1, 3, 32, 32))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(model_output, torch.rand(1, 10))\n",
    "    print(\"Your answer is correct :-)\")\n",
    "except:\n",
    "    raise AssertionError(\"Sorry your answer is wrong :( You can check the error messages above to help you locate your mistake(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 03 (ResNet)\n",
    "\n",
    "Please build a ResNet-18 model based on the code in the tutorial or use `torchvision.models.resnet18` to classify the CIFAR-10 dataset. Modify the relevant parameters from the tutorial such as learning rate, batch size, optimizer, number of epochs, loss function, etc., to achieve a better model performance. Record the train loss and validation loss and accuracy for each epoch. Then, plot them on a graph together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "resNet = ResNet18().to(device)\n",
    "\n",
    "LR = \n",
    "loss = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = \n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, resNet, loss, optimizer)\n",
    "    test(test_loader, resNet, loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 04 (GNN)\n",
    "If you haven't install torch_geometric yet, you can install it by `pip install torch_geometric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code are extracted from the tutorial, helping you prepare the data. Copy the following code to run them first and continue finishing the question.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "```\n",
    "\n",
    "Extract the data, the number of features on the node, and the number of categories of the node from the dataset, and output the number of features and the number of categories. Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "data, num_node_features, num_classes = dataset[0].to(device), dataset.num_node_features, dataset.num_classes\n",
    "print(num_node_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please define a graph convolutional network with two graph convolutional layers. \n",
    "\n",
    "- The first graph convolutional layer takes the number of node features as input channels and outputs 128 channels. The second convolutional layer takes 128 channels as input and outputs channels equal to the number of node categories for classification.\n",
    "- Both convolutional layers are activated using the sigmoid function.\n",
    "\n",
    "Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, features, hidden_dimension, classes):\n",
    "       \n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "\n",
    "hidden_dimension = \n",
    "model = GCN(num_node_features, hidden_dimension, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select appropriate hyperparameters for training, record the metrics on the validation set during training and plot them on a figure. Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = \n",
    "weight_decay = \n",
    "optimizer = \n",
    "loss_fn = \n",
    "\n",
    "precisions, recalls, f1s, losses = [], [], [], []\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    _, predicted_val = torch.max(out[data.val_mask], dim=1)\n",
    "    predicted_val = predicted_val.cpu().detach().numpy()\n",
    "    precision_val, recall_val, f1_val, _ = precision_recall_fscore_support(data.y[data.val_mask].cpu().detach().numpy(), \n",
    "                                                                           predicted_val, average='macro', zero_division=0)\n",
    "    precisions.append(precision_val)\n",
    "    recalls.append(recall_val)\n",
    "    f1s.append(f1_val)\n",
    "    print(f\"Epoch {epoch:<3d} | precision_val: {precision_val:.4f}, recall_val: {recall_val:.4f}, f1_val: {f1_val:.4f}, loss: {loss.item():.4f}\")\n",
    "\n",
    "_, predicted_test = torch.max(out[data.test_mask], dim=1)\n",
    "predicted_test = predicted_test.cpu().detach().numpy()\n",
    "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(data.y[data.test_mask].cpu().detach().numpy(), \n",
    "                                                                        predicted_test, average='macro', zero_division=0)\n",
    "print(f\"Final Test precision: {precision_test:.4f}, recall: {recall_test:.4f}, f1: {f1_test:.4f}\")\n",
    "\n",
    "epochs = range(1, len(precisions)+1)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(epochs, precisions, 'g', label='Precision')\n",
    "plt.plot(epochs, recalls, 'r', label='Recall')\n",
    "plt.plot(epochs, f1s, 'm', label='F1')\n",
    "plt.plot(epochs, losses, 'b', label='Loss')\n",
    "plt.title('Training And Validation Metrics')\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

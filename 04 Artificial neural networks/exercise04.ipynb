{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Please always run this cell first to set up the environment\n",
    "# Especially important when running in Google Colab\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # noqa: F401\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "    print(\"Running in Google Colab environment\")\n",
    "\n",
    "    REPO_NAME = \"AI-Code\"\n",
    "    REPO_URL = \"https://github.com/hku-kejintao/AI-Code.git\"\n",
    "    LESSON_DIR = \"04 Artificial neural networks\"\n",
    "\n",
    "    BASE_DIR = Path(\"/content\")\n",
    "    REPO_PATH = BASE_DIR / REPO_NAME\n",
    "    LESSON_PATH = REPO_PATH / LESSON_DIR\n",
    "\n",
    "    os.chdir(BASE_DIR)\n",
    "    if not REPO_PATH.exists():\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone {REPO_URL}\n",
    "    else:\n",
    "        print(\"Repository already exists, skip cloning.\")\n",
    "\n",
    "    if not LESSON_PATH.exists():\n",
    "        available = [p.relative_to(REPO_PATH) for p in REPO_PATH.rglob(\"*\") if p.is_dir()]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Lesson directory not found:\\n  {LESSON_DIR}\\n\\n\"\n",
    "            f\"Available directories under repo:\\n  \"\n",
    "            + \"\\n  \".join(map(str, available[:20]))\n",
    "        )\n",
    "    os.chdir(LESSON_PATH)\n",
    "\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "else:\n",
    "    print(\"Running in local / non-Colab environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04 Artificial Neural Networks\n",
    "\n",
    "In this exercise, you need to follow the requirements of each question to generate the Python code, and the following example is for reference：\n",
    "\n",
    "- Sample Question: Write a program that takes the user's name as input and prints \"Hello, [name]!\" where [name] is the user's input.\n",
    "\n",
    "- Potential Answer:\n",
    "\n",
    "```python\n",
    "    name = input(\"Enter your name: \")\n",
    "    print(\"Hello, \" + name + \"!\")\n",
    "```\n",
    "- If you enter 'David', the code will output 'Hello, David!', and this will satisfy the requirements.\n",
    "\n",
    "## Attention\n",
    "- Generally, there will be multiple answers for one question and you don't have to strictly follow the instructions in the tutorial, as long as you can make the output of the code meet the requirements of the question.\n",
    "- If possible, strive to make your code concise and avoid excessive reliance on less commonly used libraries.\n",
    "- You may need to search for information on the Internet to complete the excercise.\n",
    "- Please answer the questions in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 01: The following code are extracted from the tutorial, helping you prepare the data. Run them first and continue finishing the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchinfo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import datasets\n",
    "\n",
    "data_BART_sld = pd.read_csv('data_X.csv').iloc[:48, 1:]\n",
    "data_BART_sld = data_BART_sld.to_numpy()\n",
    "OD_BART = np.load('3d_daily.npy').sum(axis=2)[17, :48]\n",
    "# I'm copying the data definition here\n",
    "X_train = minmax_scale(data_BART_sld)[:33, :]\n",
    "y_train = minmax_scale(OD_BART)[:33].reshape(-1, 1)\n",
    "X_val = minmax_scale(data_BART_sld)[33:, :]\n",
    "y_val = minmax_scale(OD_BART)[33:].reshape(-1, 1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "# minibatch training, useful for big data, not useful here but I'm showing how to do this\n",
    "# to realize full batch training, simply set this value to be very large\n",
    "batch_size = 100 \n",
    "loader_train = torch.utils.data.DataLoader(\n",
    "    TensorDataset(X_train, y_train), batch_size, shuffle=True\n",
    ")\n",
    "iter_train = iter(loader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- Create a new neural network model with two hidden layers and a different hidden layer size (such as hid_dim = 4) and use other activation functions (such as ReLU). \n",
    "\n",
    "\n",
    "## Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 02: Use MSE as the Loss function of your model and use AdamW as your optimizer, then set an appropriate number for the epochs, train the model and print the validation loss and train loss every 20 epochs.\n",
    "\n",
    "## Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 03: Visualize your output of your model (with validation data), plot the prediction and true value together. \n",
    "\n",
    "## Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 04：Please use neural network to run classification problem\n",
    "\n",
    "In this task, you need to use ANN to perform a three-class classification task. We will use the famous Fisher's Iris data set. The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "First, the following code helps you import the necessary packages, prepare data, visualize the data and transform the data into torch dataloader. Please directly run these codes and view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "pd.plotting.scatter_matrix(df, c=iris.target, figsize=[8,8], s=16, marker='o')\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16  # NOTE: You can change the batch size here\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_set = torch.utils.data.TensorDataset(torch.tensor(train_X, dtype=torch.float32), torch.tensor(train_y, dtype=torch.int64))\n",
    "test_set = torch.utils.data.TensorDataset(torch.tensor(test_X, dtype=torch.float32), torch.tensor(test_y, dtype=torch.int64))\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, we define the ANN-based classification model, select the appropriate loss function and optimizer, and then train the model on the Iris dataset. \n",
    "\n",
    "Most frameworks have been written for you. Please: \n",
    "1. Fill in the model definition\n",
    "2. Select the loss function, optimizer and number of epochs, and then \n",
    "3. Execute these cells to complete the training.\n",
    "\n",
    "## Write your answer in the following code frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class AnnClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Your model components should be defined here\n",
    "        \n",
    "        # Your model components definition should end here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your forward propagation should be defined here\n",
    "        \n",
    "        # Your forward propagation should end here\n",
    "\n",
    "model = AnnClassifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To train a model, we need a loss function and an optimizer, and set the backpropagation part. Write your answer in the following code frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn =   # Please choose proper loss function for your task\n",
    "optimizer =   # Please choose proper optimizer for your task\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        \n",
    "\n",
    "        # Backpropagation\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (epochs). During each epoch, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =   # Please choose proper number of epochs for your task\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
